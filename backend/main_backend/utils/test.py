import torch, cv2
import numpy as np 
from PIL import Image
from ultralytics import YOLO
from torchvision import transforms
from PIL import Image, ImageDraw, ImageFont

from network import Model5Cond

# ëª¨ë¸ ë¡œë“œ ë° ë°ì´í„° ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
detector = YOLO("./weights/yolov8n-pose.pt")
net = Model5Cond(5)
weight = torch.load(
    "./weights/model_kneepushup.pth",
    map_location=torch.device("cpu"))
net.load_state_dict(weight)
net.eval()

FONT_PATH = "./NanumGothic-Regular.ttf"
FONT = ImageFont.truetype(FONT_PATH, 24)
cond_names = [{'condition': 'ì²™ì¶”ì˜ ì¤‘ë¦½', 'value': True}, {'condition': 'ì´ì™„ì‹œ íŒ”ê¿ˆì¹˜ 90ë„', 'value': True}, {'condition': 'ê°€ìŠ´ì˜ ì¶©ë¶„í•œ ì´ë™', 'value': True}, {'condition': 'ì†ì˜ ìœ„ì¹˜ ê°€ìŠ´ ì¤‘ì•™ ì—¬ë¶€', 'value': True}, {'condition': 'ê³ ê°œ ì –í˜/ìˆ™ì„ ì—¬ë¶€', 'value': True}]
video_path = r"c:\Users\human\Documents\ì¹´ì¹´ì˜¤í†¡ ë°›ì€ íŒŒì¼\kneepushup\video_kneepushup.mp4"


COND_JOINT_MAP = {
    0: [5,7,9,6,8,10],     # íŒ”ê¿ˆì¹˜/íŒ”
    1: [5,6,11,12],        # ëª¸í†µ ì •ë ¬
    2: [9,10],             # ì† ìœ„ì¹˜
    3: [11,12,13,14],      # ê¹Šì´
    4: list(range(17)),    # ì „ì²´ ì•ˆì •ì„±
}
preprocess = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((256,256)),
    transforms.ToTensor()
])

def getAllFrames(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 1:
        fps = 30  # ğŸ”¥ í•„ìˆ˜ fallback
    frames = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)
    return frames

def keypoints_npform(xy):
    if xy.shape[0]<48:
        return np.concatenate([xy, np.zeros(48 - xy.shape[0])])
    else:
        return xy

def score_to_color(s, th=0.5):
    return (0,255,0) if s >= th else (0,0,255)

def put_korean_text(frame, text, pos, color):
    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(pos, text, font=FONT, fill=(color[2], color[1], color[0]))
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

frames = getAllFrames(video_path)
frames = np.array(frames)
len(frames) # 578

# ê´€ì ˆ ì¸ì‹
res = [detector(frame, verbose = False)[0] for frame in frames]
xy_data = [i.keypoints.xy.detach().cpu().numpy() for i in res]
# í•œëª…ë§Œ ì„ íƒ
xy_data = [i[:1] if i.shape[0] > 1 else i for i in xy_data]
[i.shape for i in xy_data]
# ê´€ì ˆê°’ì´ 48ê°œë³´ë‹¤ ì‘ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›Œë„£ìŒ

xy_data = [keypoints_npform(i.reshape(-1)) for i in xy_data]
xy_data = np.array(xy_data) # (578, 48)

# Score ì‚°ì¶œ 
SEQ = 16
cond_dim = 5
scores = []
for i, img in enumerate(frames):
    img_tensor = preprocess(img).unsqueeze(0).to(device)
    cond_tensor = torch.ones((1,cond_dim), device = device)
    seq = [xy_data[j] for j in range(i-SEQ+1, i+1)]
    seq_tensor = torch.tensor(
        seq, dtype = torch.float32, device=device
        ).unsqueeze(0)
    # í˜„ì¬ì˜ ì´ë¯¸ì§€, í˜„ì¬ë¶€í„° ê³¼ê±° 16í”„ë ˆì„ê¹Œì§€ì˜ ê´€ì ˆ, 
    # ì¡°ê±´ê°’(ì²™ì¶”ì¤‘ë¦½, ì´ì™„ì‹œ íŒ”ê¿ˆì¹˜ ê°ë„, ê°€ìŠ´ì˜ ì¶©ë¶„í•œì´ë™, ì†ì˜ ìœ„ì¹˜ ê°€ìŠ´ ì¤‘ì•™ ì—¬ë¶€)
    with torch.no_grad():
        score = net(
            img_tensor, seq_tensor, cond_tensor
            ).squeeze().detach().cpu().numpy()
    scores.append(score)

scores = np.array(scores) # 578, 5

#  ì‹œê°í™”
out_video_path= "ex.mp4"
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
W, H = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
writer = cv2.VideoWriter(out_video_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (W,H))
export_video = frames.copy()
for img, score, key_point in zip(export_video, scores, xy_data):
    # ê´€ì ˆë³„ ìŠ¤ì½”ì–´ ìƒ‰ìƒ ì„¤ì •
    joint_colors = {}
    for c_idx, joints in COND_JOINT_MAP.items():
        for j in joints:
            joint_colors[j] = score_to_color(score[c_idx])
    
    # ë²„ë¦¼ ì²˜ë¦¬
    pts = key_point.reshape(-1,2).astype(int)
    for j,(x,y) in enumerate(pts):
        cv2.circle(img, (x,y), 4, joint_colors.get(j,(200,200,200)), -1)
    
    y0 = 30
    for name, s in zip(cond_names, score):
        img = put_korean_text(img, f"{name}: {s:.2f}", (20,y0), score_to_color(s))
        y0 += 28
    writer.write(img)
writer.release()
