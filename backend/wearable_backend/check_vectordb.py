#!/usr/bin/env python3
"""
VectorDB ë°ì´í„° í™•ì¸ ìŠ¤í¬ë¦½íŠ¸ (í™˜ê²½ë³€ìˆ˜ ë…ë¦½ ë²„ì „)
ChromaDBì— ì €ì¥ëœ ë°ì´í„°ì˜ ë‚ ì§œ, ì¶œì²˜, í”Œë«í¼, ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.
OpenAI API ì—†ì´ ì§ì ‘ ChromaDBì— ì ‘ê·¼í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
from datetime import datetime

# ë°±ì—”ë“œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.abspath("."))

# âœ… .env íŒŒì¼ ë¡œë“œ (ì„ íƒì )
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass
except Exception as e:
    pass

from app.core.vector_store import collection


def print_header(title):
    """í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 100)
    print(f"  {title}")
    print("=" * 100)


def format_data_value(key, value):
    """ë°ì´í„° ê°’ í¬ë§·íŒ…"""
    if isinstance(value, (int, float)):
        if key in ["weight", "bmi", "body_fat", "lean_body"]:
            return f"{value:.1f}"
        elif key in ["distance_km"]:
            return f"{value:.2f} km"
        elif key in ["steps", "flights"]:
            return f"{value:,}"
        elif key in ["active_calories", "total_calories", "calories_intake"]:
            return f"{value} kcal"
        elif key in ["sleep_hr"]:
            return f"{value} ì‹œê°„"
        elif key in ["sleep_min", "exercise_min"]:
            return f"{value} ë¶„"
        else:
            return str(value)
    return str(value)


def get_date(user_id: str, date: str):
    """
    íŠ¹ì • ë‚ ì§œ ë°ì´í„° ì¡°íšŒ (í•¨ìˆ˜ë¡œ ì œê³µ)

    Args:
        user_id: ì‚¬ìš©ì ID
        date: ë‚ ì§œ (YYYY-MM-DD)

    Returns:
        dict: ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None

    Usage:
        from check_vectordb import get_date
        data = get_date("user@example.com", "2025-12-16")
        print(data['summary_text'])
    """
    try:
        result = collection.get(where={"$and": [{"user_id": user_id}, {"date": date}]})

        if not result or not result["metadatas"]:
            return None

        metadata = result["metadatas"][0]
        summary_json = metadata.get("summary_json", "{}")

        try:
            summary_dict = json.loads(summary_json)
        except:
            summary_dict = {}

        return {
            "date": metadata.get("date"),
            "source": metadata.get("source"),
            "platform": metadata.get("platform"),
            "health_score": metadata.get("health_score"),
            "recommended_intensity": metadata.get("recommended_intensity"),
            "updated_at": metadata.get("updated_at"),
            "summary_text": summary_dict.get("summary_text", ""),
            "raw": summary_dict.get("raw", {}),
        }
    except Exception as e:
        print(f"[ERROR] {e}")
        return None


def view_specific_date(user_id: str, target_date: str):
    """íŠ¹ì • ë‚ ì§œ ë°ì´í„° ìƒì„¸ ì¶œë ¥"""
    print_header(f"ğŸ” íŠ¹ì • ë‚ ì§œ ì¡°íšŒ: {target_date}")

    data = get_date(user_id, target_date)

    if not data:
        print(f"\nâš ï¸ {target_date} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"\nğŸ“… ë‚ ì§œ: {data['date']}\n")

    # ë©”íƒ€ ì •ë³´
    print(f"ğŸ“Œ ë©”íƒ€ ì •ë³´:")
    print(f"   ì¶œì²˜(Source):     {data['source']}")
    print(f"   í”Œë«í¼(Platform): {data['platform']}")
    print(f"   ì—…ë°ì´íŠ¸:         {data['updated_at']}")
    print(f"   ê±´ê°• ì ìˆ˜:        {data['health_score']}ì ")
    print(f"   ê¶Œì¥ ê°•ë„:        {data['recommended_intensity']}\n")

    # ìš”ì•½
    if data["summary_text"]:
        print(f"ğŸ“ ìš”ì•½:")
        print(f"   {data['summary_text']}\n")

    # ìƒì„¸ ë°ì´í„° (0ì´ ì•„ë‹Œ ê°’ë§Œ)
    raw = data["raw"]
    if raw:
        print(f"ğŸ“Š ìƒì„¸ ë°ì´í„° (0ì´ ì•„ë‹Œ ê°’ë§Œ):\n")

        has_data = False
        for key, value in sorted(raw.items()):
            if value and value != 0:
                has_data = True
                formatted_value = format_data_value(key, value)
                print(f"   {key:25s}: {formatted_value}")

        if not has_data:
            print("   (ëª¨ë“  ê°’ì´ 0ì…ë‹ˆë‹¤)")

    print(f"\n{'='*100}\n")


def view_all_data(show_summary=False):
    """VectorDBì˜ ëª¨ë“  ë°ì´í„° í™•ì¸ (ì¶œì²˜ ë° í”Œë«í¼ í¬í•¨)"""
    print_header("ğŸ” VectorDB ì „ì²´ ë°ì´í„° ì¡°íšŒ")

    try:
        count = collection.count()
        print(f"\nğŸ“Š ì´ ì €ì¥ëœ ë°ì´í„°: {count}ê°œ\n")

        if count == 0:
            print("âš ï¸ VectorDBì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return

        # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_data = collection.get()

        # ì‚¬ìš©ìë³„ ê·¸ë£¹í™”
        user_data = {}
        for metadata in all_data["metadatas"]:
            user_id = metadata.get("user_id", "unknown")
            if user_id not in user_data:
                user_data[user_id] = []
            user_data[user_id].append(metadata)

        # ì‚¬ìš©ìë³„ ì¶œë ¥
        for user_id, data_list in user_data.items():
            print(f"\nğŸ‘¤ User: {user_id}")
            print(f"   ë°ì´í„° ê°œìˆ˜: {len(data_list)}ê°œ\n")

            # ë‚ ì§œë³„ ì •ë ¬
            sorted_data = sorted(
                data_list, key=lambda x: x.get("date", ""), reverse=True
            )

            # ë‚ ì§œë³„ ê·¸ë£¹í™” (ê°™ì€ ë‚ ì§œ ì—¬ëŸ¬ ê±´ í™•ì¸)
            date_groups = {}
            for item in sorted_data:
                date = item.get("date", "unknown")
                if date not in date_groups:
                    date_groups[date] = []
                date_groups[date].append(item)

            # ë‚ ì§œë³„ ì¶œë ¥ (ìµœëŒ€ 20ê°œë§Œ)
            displayed = 0
            for date, items in list(date_groups.items())[:20]:
                if len(items) == 1:
                    item = items[0]
                    source = item.get("source", "unknown")
                    platform = item.get("platform", "unknown")
                    score = item.get("health_score", 0)
                    updated = item.get("updated_at", "")

                    print(f"   ğŸ“… {date}")
                    print(
                        f"      ì¶œì²˜: {source:15s} | í”Œë«í¼: {platform:8s} | ê±´ê°•ì ìˆ˜: {score}ì  | ì—…ë°ì´íŠ¸: {updated}"
                    )
                else:
                    # ê°™ì€ ë‚ ì§œì— ì—¬ëŸ¬ ê±´
                    print(f"   ğŸ“… {date} âš ï¸ ì¤‘ë³µ {len(items)}ê±´:")
                    for idx, item in enumerate(items, 1):
                        source = item.get("source", "unknown")
                        platform = item.get("platform", "unknown")
                        score = item.get("health_score", 0)
                        updated = item.get("updated_at", "")
                        print(
                            f"      [{idx}] ì¶œì²˜: {source:15s} | í”Œë«í¼: {platform:8s} | ê±´ê°•ì ìˆ˜: {score}ì  | ì—…ë°ì´íŠ¸: {updated}"
                        )

                displayed += 1

            if len(date_groups) > 20:
                print(f"\n   ... ì™¸ {len(date_groups) - 20}ê°œ ë‚ ì§œ")

            if show_summary:
                print(
                    f"\n   ğŸ’¡ ìƒì„¸ ë³´ê¸°: python check_vectordb.py --user {user_id} --detail"
                )

        print("\n" + "=" * 100)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback

        traceback.print_exc()


def view_user_data(user_id: str, detailed=False, show_all_fields=False):
    """íŠ¹ì • ì‚¬ìš©ìì˜ ë°ì´í„° ìƒì„¸ ì¡°íšŒ (ì¶œì²˜ ë° í”Œë«í¼ í¬í•¨) - OpenAI API ë¶ˆí•„ìš”"""
    print_header(f"ğŸ” User '{user_id}' ë°ì´í„° ìƒì„¸ ì¡°íšŒ")

    try:
        # âœ… OpenAI API ì—†ì´ ì§ì ‘ ì¡°íšŒ
        all_data = collection.get(where={"user_id": user_id})

        if not all_data or not all_data["metadatas"]:
            print("\nâš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return

        metadatas = all_data["metadatas"]
        print(f"\nğŸ“Š ì´ {len(metadatas)}ê°œ ë°ì´í„°\n")

        # ë‚ ì§œë³„ ì •ë ¬
        sorted_data = sorted(metadatas, key=lambda x: x.get("date", ""), reverse=True)

        for i, metadata in enumerate(sorted_data, 1):
            date = metadata.get("date", "unknown")
            source = metadata.get("source", "unknown")
            platform = metadata.get("platform", "unknown")
            updated = metadata.get("updated_at", "")
            health_score = metadata.get("health_score", 0)
            intensity = metadata.get("recommended_intensity", "ì¤‘")

            # summary_json íŒŒì‹±
            summary_json = metadata.get("summary_json", "{}")
            try:
                summary_dict = json.loads(summary_json)
            except:
                summary_dict = {}

            raw = summary_dict.get("raw", {})
            summary_text = summary_dict.get("summary_text", "")

            print(f"\n{'='*100}")
            print(f"ğŸ“… [{i}] ë‚ ì§œ: {date}")
            print(f"{'='*100}")

            # âœ… ë©”íƒ€ ì •ë³´
            print(f"\nğŸ“Œ ë©”íƒ€ ì •ë³´:")
            print(f"   ì¶œì²˜(Source):     {source}")
            print(f"   í”Œë«í¼(Platform): {platform}")
            print(f"   ì—…ë°ì´íŠ¸:         {updated}")
            print(f"   ê±´ê°• ì ìˆ˜:        {health_score}ì ")
            print(f"   ê¶Œì¥ ê°•ë„:        {intensity}")

            # ìš”ì•½ í…ìŠ¤íŠ¸
            if summary_text:
                print(f"\nğŸ“ ìš”ì•½:")
                if len(summary_text) > 200:
                    print(f"   {summary_text[:200]}...")
                else:
                    print(f"   {summary_text}")

            if detailed and raw:
                # ìƒì„¸ ë°ì´í„° ì¶œë ¥
                print(f"\nğŸ“Š ìƒì„¸ ë°ì´í„° ({len(raw)}ê°œ í•­ëª©):")

                if show_all_fields:
                    # ëª¨ë“  í•„ë“œ ì¶œë ¥
                    for key, value in sorted(raw.items()):
                        formatted_value = format_data_value(key, value)
                        print(f"   {key:25s}: {formatted_value}")
                else:
                    # ì£¼ìš” í•„ë“œë§Œ ì¶œë ¥
                    key_fields = [
                        "sleep_hr",
                        "sleep_min",
                        "steps",
                        "distance_km",
                        "active_calories",
                        "heart_rate",
                        "resting_heart_rate",
                        "weight",
                        "bmi",
                        "exercise_min",
                    ]

                    available_fields = [k for k in key_fields if k in raw]
                    other_fields = [k for k in raw.keys() if k not in key_fields]

                    if available_fields:
                        print("\n   ğŸ“Œ ì£¼ìš” ì§€í‘œ:")
                        for key in available_fields:
                            value = raw[key]
                            if value and value != 0:  # 0ì´ ì•„ë‹Œ ê°’ë§Œ í‘œì‹œ
                                formatted_value = format_data_value(key, value)
                                print(f"      {key:25s}: {formatted_value}")

                    if other_fields:
                        non_zero_others = [
                            k for k in other_fields if raw.get(k) and raw.get(k) != 0
                        ]
                        if non_zero_others:
                            print(
                                f"\n   ğŸ’¡ ê¸°íƒ€ {len(non_zero_others)}ê°œ í•­ëª©: {', '.join(non_zero_others[:5])}..."
                            )
                            print(f"      (ì „ì²´ ë³´ê¸°: --all-fields ì˜µì…˜ ì‚¬ìš©)")

        print("\n" + "=" * 100)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback

        traceback.print_exc()


def check_duplicates(user_id: str = None):
    """ê°™ì€ ë‚ ì§œ ì¤‘ë³µ ë°ì´í„° í™•ì¸"""
    print_header("ğŸ” ì¤‘ë³µ ë°ì´í„° í™•ì¸")

    try:
        all_data = collection.get()

        if user_id:
            # íŠ¹ì • ì‚¬ìš©ìë§Œ í•„í„°ë§
            filtered_metadatas = [
                m for m in all_data["metadatas"] if m.get("user_id") == user_id
            ]
        else:
            filtered_metadatas = all_data["metadatas"]

        # ë‚ ì§œë³„ ê·¸ë£¹í™”
        date_groups = {}
        for metadata in filtered_metadatas:
            uid = metadata.get("user_id", "unknown")
            date = metadata.get("date", "unknown")
            key = f"{uid}_{date}"

            if key not in date_groups:
                date_groups[key] = []
            date_groups[key].append(metadata)

        # ì¤‘ë³µ ì°¾ê¸°
        duplicates = {k: v for k, v in date_groups.items() if len(v) > 1}

        if not duplicates:
            print("\nâœ… ì¤‘ë³µ ë°ì´í„° ì—†ìŒ!")
            return

        print(f"\nâš ï¸ ì´ {len(duplicates)}ê°œ ë‚ ì§œì— ì¤‘ë³µ ë°ì´í„° ë°œê²¬:\n")

        for key, items in duplicates.items():
            user_id, date = key.split("_", 1)
            print(f"\nğŸ‘¤ User: {user_id} | ğŸ“… ë‚ ì§œ: {date} | ì¤‘ë³µ: {len(items)}ê±´")

            for idx, item in enumerate(items, 1):
                source = item.get("source", "unknown")
                platform = item.get("platform", "unknown")
                updated = item.get("updated_at", "")
                score = item.get("health_score", 0)
                print(
                    f"   [{idx}] ì¶œì²˜: {source:15s} | í”Œë«í¼: {platform:8s} | ê±´ê°•ì ìˆ˜: {score}ì  | ì—…ë°ì´íŠ¸: {updated}"
                )

        print("\n" + "=" * 100)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback

        traceback.print_exc()


def check_chroma_location():
    """ChromaDB ì €ì¥ ìœ„ì¹˜ í™•ì¸"""
    print_header("ğŸ“ ChromaDB ì €ì¥ ìœ„ì¹˜ í™•ì¸")

    try:
        chroma_dir = "./chroma_data"
        abs_path = os.path.abspath(chroma_dir)

        print(f"\nê²½ë¡œ: {abs_path}")

        if os.path.exists(abs_path):
            print(f"ìƒíƒœ: âœ… ì¡´ì¬í•¨")

            # ë””ë ‰í† ë¦¬ í¬ê¸°
            total_size = 0
            file_count = 0
            for root, dirs, files in os.walk(abs_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    total_size += os.path.getsize(file_path)
                    file_count += 1

            print(f"íŒŒì¼: {file_count}ê°œ")
            print(
                f"í¬ê¸°: {total_size / 1024:.2f} KB ({total_size / (1024*1024):.2f} MB)"
            )
        else:
            print(f"ìƒíƒœ: âŒì¡´ì¬í•˜ì§€ ì•ŠìŒ")

        print("\n" + "=" * 100)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def show_date_range(user_id: str = None):
    """ë‚ ì§œ ë²”ìœ„ í™•ì¸"""
    print_header("ğŸ“… ë‚ ì§œ ë²”ìœ„ í™•ì¸")

    try:
        if user_id:
            all_data = collection.get(where={"user_id": user_id})
        else:
            all_data = collection.get()

        metadatas = all_data.get("metadatas", [])

        if not metadatas:
            print("\nâš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return

        dates = [m.get("date") for m in metadatas if m.get("date")]
        dates = sorted(set(dates))

        if dates:
            print(f"\nğŸ“Š ì´ {len(dates)}ê°œ ë‚ ì§œ")
            print(f"ğŸ“… ë²”ìœ„: {dates[0]} ~ {dates[-1]}")
            print(f"\nìµœê·¼ 10ê°œ ë‚ ì§œ:")
            for date in dates[-10:]:
                date_items = [m for m in metadatas if m.get("date") == date]
                sources = set([m.get("source", "unknown") for m in date_items])
                platforms = set([m.get("platform", "unknown") for m in date_items])
                print(
                    f"   {date} | ê±´ìˆ˜: {len(date_items)} | ì¶œì²˜: {', '.join(sources)} | í”Œë«í¼: {', '.join(platforms)}"
                )

        print("\n" + "=" * 100)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="VectorDB ë°ì´í„° í™•ì¸ (ì¶œì²˜ ë° í”Œë«í¼ ì •ë³´ í¬í•¨)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python check_vectordb.py --all                          # ì „ì²´ ë°ì´í„° ìš”ì•½
  python check_vectordb.py --user a@aaa.com               # íŠ¹ì • ì‚¬ìš©ì ë°ì´í„°
  python check_vectordb.py --user a@aaa.com --detail      # ìƒì„¸ ì •ë³´
  python check_vectordb.py --user a@aaa.com --detail --all-fields  # ëª¨ë“  í•„ë“œ
  python check_vectordb.py --date 2025-12-16 --user a@aaa.com      # íŠ¹ì • ë‚ ì§œ
  python check_vectordb.py --duplicates                   # ì¤‘ë³µ ë°ì´í„° í™•ì¸
  python check_vectordb.py --dates                        # ë‚ ì§œ ë²”ìœ„ í™•ì¸
  python check_vectordb.py --location                     # ChromaDB ìœ„ì¹˜

Python ì¸í„°í”„ë¦¬í„°ì—ì„œ ì‚¬ìš©:
  from check_vectordb import get_date
  data = get_date("user@example.com", "2025-12-16")
  print(data['summary_text'])
        """,
    )

    parser.add_argument("--all", action="store_true", help="ì „ì²´ ë°ì´í„° ìš”ì•½ ë³´ê¸°")
    parser.add_argument("--user", type=str, help="íŠ¹ì • ì‚¬ìš©ì ë°ì´í„° í™•ì¸")
    parser.add_argument("--date", type=str, help="íŠ¹ì • ë‚ ì§œ ì¡°íšŒ (YYYY-MM-DD)")
    parser.add_argument("--detail", action="store_true", help="ìƒì„¸ ì •ë³´ ë³´ê¸°")
    parser.add_argument(
        "--all-fields", action="store_true", help="ëª¨ë“  ë°ì´í„° í•„ë“œ ë³´ê¸°"
    )
    parser.add_argument("--duplicates", action="store_true", help="ì¤‘ë³µ ë°ì´í„° í™•ì¸")
    parser.add_argument("--dates", action="store_true", help="ë‚ ì§œ ë²”ìœ„ í™•ì¸")
    parser.add_argument("--location", action="store_true", help="ChromaDB ìœ„ì¹˜ í™•ì¸")

    args = parser.parse_args()

    if args.date and args.user:
        # íŠ¹ì • ë‚ ì§œ ì¡°íšŒ
        view_specific_date(args.user, args.date)
    elif args.all:
        view_all_data(show_summary=True)
    elif args.user:
        view_user_data(args.user, detailed=args.detail, show_all_fields=args.all_fields)
    elif args.duplicates:
        check_duplicates()
    elif args.dates:
        show_date_range()
    elif args.location:
        check_chroma_location()
    else:
        # ê¸°ë³¸: ì „ì²´ ìš”ì•½
        check_chroma_location()
        print()
        view_all_data(show_summary=True)
