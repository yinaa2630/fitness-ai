"""
Fixed Responses - ê³ ì •í˜• ì§ˆë¬¸ ì‘ë‹µ ìƒì„±ê¸° (í’ˆì§ˆ ê°œì„ )
ì†ë„ ìœ ì§€: ê° ì§ˆë¬¸ë‹¹ LLM 1íšŒ í˜¸ì¶œ
í’ˆì§ˆ í–¥ìƒ: ê·œì¹™ ê¸°ë°˜ í•´ì„ + ìƒì„¸ í”„ë¡¬í”„íŠ¸
"""

import json
from openai import OpenAI
import os

from app.config import LLM_MODEL_MAIN, LLM_TEMPERATURE, LLM_MAX_TOKENS
from app.core.chatbot_engine.persona import get_persona_prompt
from app.core.vector_store import search_similar_summaries
from app.core.llm_analysis import run_llm_analysis
from app.core.health_interpreter import (
    interpret_health_data,
    build_health_context_for_llm,
    calculate_health_score,
    interpret_sleep,
    interpret_heart_rate,
    interpret_activity,
)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def generate_fixed_response(user_id: str, question_type: str, character: str):
    """
    ê³ ì •í˜• ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì—”ì§„ (í’ˆì§ˆ ê°œì„  ë²„ì „)
    """

    persona = get_persona_prompt(character)

    # VectorDBì—ì„œ ìµœê·¼ summary ê²€ìƒ‰
    vector_result = search_similar_summaries(
        query_dict={"query": "health summary"}, user_id=user_id, top_k=5
    )

    summaries = vector_result.get("similar_days", []) or []

    # summary ì—†ì„ ê²½ìš° fallback
    if not summaries:
        return _get_no_data_response(character)

    # ìµœê·¼ summary ë°ì´í„° ì¶”ì¶œ
    recent = summaries[0]
    recent_raw = recent.get("raw", {})
    recent_summary_text = recent.get("summary_text", "")
    recent_date = recent.get("date", "ìµœê·¼")

    # ê·œì¹™ ê¸°ë°˜ ê±´ê°• í•´ì„ (LLM í˜¸ì¶œ ì—†ìŒ!)
    health_interpretation = interpret_health_data(recent_raw)
    health_context = build_health_context_for_llm(recent_raw)

    # ================================
    # 1) ì£¼ê°„ ë¦¬í¬íŠ¸
    # ================================
    if question_type == "weekly_report":
        return _generate_weekly_report(
            persona,
            character,
            recent_raw,
            summaries,
            health_interpretation,
            health_context,
        )

    # ================================
    # 2) ì˜¤ëŠ˜ ìš´ë™ ì¶”ì²œ
    # ================================
    if question_type == "today_recommendation":
        return _generate_today_recommendation(
            character, recent_raw, recent_summary_text, summaries, health_interpretation
        )

    # ================================
    # 3) ê±¸ìŒìˆ˜ (ì§€ë‚œì£¼)
    # ================================
    if question_type == "weekly_steps":
        return _generate_steps_report(
            persona, character, recent_raw, summaries, health_interpretation
        )

    # ================================
    # 4) ìˆ˜ë©´ ë¶„ì„
    # ================================
    if question_type == "sleep_report":
        return _generate_sleep_report(
            persona, character, recent_raw, summaries, health_interpretation
        )

    # ================================
    # 5) ì‹¬ë°•ìˆ˜ ë¶„ì„
    # ================================
    if question_type == "heart_rate":
        return _generate_heart_rate_report(
            persona, character, recent_raw, health_interpretation
        )

    # ================================
    # 6) ê±´ê°• ì ìˆ˜
    # ================================
    if question_type == "health_score":
        return _generate_health_score_report(
            persona, character, recent_raw, health_interpretation
        )

    return "âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” question_type ì…ë‹ˆë‹¤."


# ============================================================
# ë‚´ë¶€ í•¨ìˆ˜ë“¤
# ============================================================


def _get_no_data_response(character: str) -> str:
    """ë°ì´í„° ì—†ì„ ë•Œ ìºë¦­í„°ë³„ ì‘ë‹µ"""
    responses = {
        "devil_coach": "ì¸ê°„, ë°ì´í„°ê°€ ì—†ì–ì•„! í—¬ìŠ¤ì»¤ë„¥íŠ¸ ZIP íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ë¼. ê·¸ë˜ì•¼ ì§€ì˜¥ í›ˆë ¨ì„ ì‹œì‘í•  ìˆ˜ ìˆì§€!",
        "angel_coach": "ì•„ì§ ì €ì¥ëœ ê±´ê°• ë°ì´í„°ê°€ ì—†ì–´ìš” âœ¨ í—¬ìŠ¤ì»¤ë„¥íŠ¸ ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œë©´ í•¨ê»˜ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤!",
        "booster_coach": "ì•—! ë°ì´í„°ê°€ ì—†ë„¤ìš”!! ğŸ”¥ í—¬ìŠ¤ì»¤ë„¥íŠ¸ ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì—„ì²­ë‚œ ë¶„ì„ì„ ë³´ì—¬ë“œë¦´ê²Œìš”!! ë ›ì¸ ê³ !!",
    }
    return responses.get(character, responses["booster_coach"])


def _generate_weekly_report(
    persona, character, raw, summaries, health_info, health_context
):
    """ì£¼ê°„ ê±´ê°• ë¦¬í¬íŠ¸ ìƒì„±"""

    # ì—¬ëŸ¬ ë‚ ì˜ ë°ì´í„° ì§‘ê³„
    total_steps = 0
    total_calories = 0
    avg_sleep = 0
    days_count = len(summaries)

    for day in summaries[:7]:
        day_raw = day.get("raw", {})
        total_steps += day_raw.get("steps", 0)
        total_calories += day_raw.get("active_calories", 0)
        avg_sleep += day_raw.get("sleep_hr", 0)

    if days_count > 0:
        avg_sleep = avg_sleep / days_count

    # ê±´ê°• ì ìˆ˜
    score_info = health_info.get("health_score", {})

    prompt = f"""
{persona}

ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì´ë²ˆ ì£¼ ê±´ê°• ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

## ì‚¬ìš©ì ê±´ê°• ë°ì´í„° ìš”ì•½

### ìµœê·¼ ì¸¡ì • ë°ì´í„°
{health_context}

### ì£¼ê°„ ì§‘ê³„ (ìµœê·¼ {days_count}ì¼)
â€¢ ì´ ê±¸ìŒìˆ˜: {total_steps:,}ë³´
â€¢ ì¼ í‰ê·  ê±¸ìŒ: {total_steps // max(days_count, 1):,}ë³´
â€¢ ì´ ì†Œëª¨ ì¹¼ë¡œë¦¬: {total_calories:,}kcal
â€¢ í‰ê·  ìˆ˜ë©´: {avg_sleep:.1f}ì‹œê°„

### ì¢…í•© ê±´ê°• ì ìˆ˜
â€¢ ì ìˆ˜: {score_info.get('score', 50)}ì 
â€¢ ë“±ê¸‰: {score_info.get('grade', 'C')} ({score_info.get('grade_text', 'ë³´í†µ')})
â€¢ í‰ê°€ ìš”ì†Œ: {', '.join(score_info.get('factors', [])[:3])}

## ì‘ì„± ì§€ì¹¨
1. ìºë¦­í„° ë§íˆ¬ë¥¼ ë°˜ë“œì‹œ ìœ ì§€í•˜ì„¸ìš”
2. ê¸ì •ì ì¸ ë¶€ë¶„ê³¼ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ê· í˜•ìˆê²Œ ì–¸ê¸‰í•˜ì„¸ìš”
3. êµ¬ì²´ì ì¸ ìˆ«ìë¥¼ í™œìš©í•´ ì„¤ëª…í•˜ì„¸ìš”
4. ë‹¤ìŒ ì£¼ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì¡°ì–¸ì„ í¬í•¨í•˜ì„¸ìš”
5. 3-4ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš” (ë¦¬ìŠ¤íŠ¸/ë¶ˆë¦¿ ê¸ˆì§€)
"""

    resp = client.chat.completions.create(
        model=LLM_MODEL_MAIN,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=LLM_MAX_TOKENS,
        temperature=LLM_TEMPERATURE,
    )
    return resp.choices[0].message.content


def _generate_today_recommendation(
    character, raw, summary_text, summaries, health_info
):
    """ì˜¤ëŠ˜ ìš´ë™ ì¶”ì²œ - í…œí”Œë¦¿ ê¸°ë°˜ (LLM ì¶”ê°€ í˜¸ì¶œ ì—†ìŒ!)"""

    # LLM ë¶„ì„ 1íšŒ í˜¸ì¶œ
    routine = run_llm_analysis(
        summary={"raw": raw, "summary_text": summary_text},
        rag_result={"similar_days": summaries},
        difficulty_level="ì¤‘",
        duration_min=30,
    )

    analysis = routine.get("analysis", "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì— ë§ëŠ” ë£¨í‹´ì…ë‹ˆë‹¤.")
    routine_data = routine.get("ai_recommended_routine", {})
    items = routine_data.get("items", [])
    total_time = routine_data.get("total_time_min", 30)
    total_cal = routine_data.get("total_calories", 150)

    # ê±´ê°• ìƒíƒœ ìš”ì•½
    exercise_rec = health_info.get("exercise_recommendation", {})
    sleep_status = health_info.get("sleep", {}).get("level", "")

    # ìºë¦­í„°ë³„ í…œí”Œë¦¿
    templates = {
        "devil_coach": {
            "intro": "ì¸ê°„, ì˜¤ëŠ˜ ì§€ì˜¥ í›ˆë ¨ ë©”ë‰´ë‹¤. ê°ì˜¤í•´ë¼!",
            "sleep_comment": {
                "ì‹¬ê°í•œ ìˆ˜ë©´ ë¶€ì¡±": "ìˆ˜ë©´ì´ ë¶€ì¡±í•˜ì§€ë§Œ... í•‘ê³„ëŠ” ì•ˆ ë°›ëŠ”ë‹¤!",
                "ìˆ˜ë©´ ë¶€ì¡±": "ì¢€ í”¼ê³¤í•´ ë³´ì´ëŠ”êµ°. ê·¸ë˜ë„ ë´ì£¼ì§„ ì•Šì•„!",
                "ì¶©ë¶„í•œ ìˆ˜ë©´": "ì˜ ì¤êµ°. ì˜¤ëŠ˜ì€ ì œëŒ€ë¡œ êµ´ë ¤ì£¼ì§€!",
                "default": "",
            },
            "outro": "ì´ ì •ë„ëŠ” ì›Œë°ì—…ì´ë‹¤. ì§„ì§œ ì§€ì˜¥ì€ ì•„ì§ ì‹œì‘ë„ ì•ˆ í–ˆì–´!",
        },
        "angel_coach": {
            "intro": "ì˜¤ëŠ˜ë„ í•¨ê»˜ ê±´ê°•í•œ í•˜ë£¨ë¥¼ ë§Œë“¤ì–´ë´ìš” âœ¨",
            "sleep_comment": {
                "ì‹¬ê°í•œ ìˆ˜ë©´ ë¶€ì¡±": "ìˆ˜ë©´ì´ ë¶€ì¡±í•˜ì…¨ë„¤ìš”. ë¬´ë¦¬í•˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ í•´ë´ìš”.",
                "ìˆ˜ë©´ ë¶€ì¡±": "ì¡°ê¸ˆ í”¼ê³¤í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”. ì²œì²œíˆ ì§„í–‰í•´ìš”.",
                "ì¶©ë¶„í•œ ìˆ˜ë©´": "í‘¹ ì£¼ë¬´ì…¨ë„¤ìš”! ì˜¤ëŠ˜ ì¢‹ì€ ì»¨ë””ì…˜ì´ì—ìš”.",
                "default": "",
            },
            "outro": "ë‹¹ì‹ ì€ ì´ë¯¸ ì˜ í•˜ê³  ìˆì–´ìš”. ì²œì²œíˆ, ê·¸ëŸ¬ë‚˜ í™•ì‹¤í•˜ê²Œ! ğŸ’ª",
        },
        "booster_coach": {
            "intro": "ë ›ì¸ ê³ ì˜¤ì˜¤ì˜¤!! ğŸ”¥ ì˜¤ëŠ˜ì˜ ë¶ˆê½ƒ ë£¨í‹´ ì‹œì‘í•œë‹¤!!",
            "sleep_comment": {
                "ì‹¬ê°í•œ ìˆ˜ë©´ ë¶€ì¡±": "ìˆ˜ë©´ì´ ë¶€ì¡±í•´ë„ ì—´ì •ì€ ì¶©ë§Œ!! ê°€ë³´ìê³ !!",
                "ìˆ˜ë©´ ë¶€ì¡±": "ì‚´ì§ í”¼ê³¤í•´ë„ ê´œì°®ì•„!! ì›€ì§ì´ë©´ ì—ë„ˆì§€ê°€ ìƒê²¨!!",
                "ì¶©ë¶„í•œ ìˆ˜ë©´": "ì»¨ë””ì…˜ ìµœê³ !! ì˜¤ëŠ˜ ê¸°ë¡ ê°±ì‹  ê°€ì¦ˆì•„!!",
                "default": "",
            },
            "outro": "íŒŒì›Œ! íŒŒì›Œ! íŒŒì›Œ! ì˜¤ëŠ˜ë„ ì™„ì „ ì°¢ì—ˆë‹¤!! ğŸ‰",
        },
    }

    template = templates.get(character, templates["booster_coach"])
    sleep_comment = template["sleep_comment"].get(
        sleep_status, template["sleep_comment"]["default"]
    )

    # ìš´ë™ ëª©ë¡ í¬ë§·íŒ…
    exercise_lines = []
    for i, item in enumerate(items, 1):
        name = item.get("exercise_name", "ìš´ë™")
        duration = item.get("duration_sec", 30)
        sets = item.get("set_count", 3)
        rest = item.get("rest_sec", 10)
        met = item.get("met", 4)
        exercise_lines.append(
            f"  {i}. {name} - {duration}ì´ˆ x {sets}ì„¸íŠ¸ (íœ´ì‹ {rest}ì´ˆ) [MET {met}]"
        )

    exercises_text = (
        "\n".join(exercise_lines) if exercise_lines else "  - ê¸°ë³¸ ìŠ¤íŠ¸ë ˆì¹­ ë£¨í‹´"
    )

    # ìµœì¢… ì‘ë‹µ ì¡°í•©
    response_parts = [template["intro"]]

    if sleep_comment:
        response_parts.append(f"\n{sleep_comment}")

    response_parts.append(
        f"""

ğŸ“Š ì˜¤ëŠ˜ì˜ ë¶„ì„: {analysis}

â±ï¸ ì´ ìš´ë™ ì‹œê°„: {total_time}ë¶„
ğŸ”¥ ì˜ˆìƒ ì†Œëª¨ ì¹¼ë¡œë¦¬: {total_cal}kcal
ğŸ’ª ê¶Œì¥ ê°•ë„: {exercise_rec.get('recommended_level', 'ì¤‘')}

ğŸ‹ï¸ ì¶”ì²œ ìš´ë™:
{exercises_text}

{template['outro']}"""
    )

    return "".join(response_parts)


def _generate_steps_report(persona, character, raw, summaries, health_info):
    """ê±¸ìŒìˆ˜ ë¶„ì„ ë¦¬í¬íŠ¸"""

    # ì—¬ëŸ¬ ë‚ ì˜ ê±¸ìŒìˆ˜ ì§‘ê³„
    steps_data = []
    for day in summaries[:7]:
        day_raw = day.get("raw", {})
        steps_data.append(
            {
                "date": day.get("date", ""),
                "steps": day_raw.get("steps", 0),
                "distance": day_raw.get("distance_km", 0),
            }
        )

    total_steps = sum(d["steps"] for d in steps_data)
    avg_steps = total_steps // max(len(steps_data), 1)
    total_distance = sum(d["distance"] for d in steps_data)

    activity_info = health_info.get("activity", {})

    prompt = f"""
{persona}

ì‚¬ìš©ìì˜ ì§€ë‚œì£¼ ê±¸ìŒìˆ˜ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

## ê±¸ìŒìˆ˜ ë°ì´í„°

### ìµœê·¼ {len(steps_data)}ì¼ ê¸°ë¡
{json.dumps(steps_data, ensure_ascii=False, indent=2)}

### ì§‘ê³„
â€¢ ì´ ê±¸ìŒìˆ˜: {total_steps:,}ë³´
â€¢ ì¼ í‰ê· : {avg_steps:,}ë³´
â€¢ ì´ ì´ë™ê±°ë¦¬: {total_distance:.2f}km

### í™œë™ëŸ‰ í‰ê°€
â€¢ í™œë™ ë ˆë²¨: {activity_info.get('activity_level', 'unknown')}
â€¢ ë¶„ì„: {activity_info.get('message', '')}
â€¢ ê¶Œì¥ì‚¬í•­: {activity_info.get('recommendation', '')}

## ì‘ì„± ì§€ì¹¨
1. ìºë¦­í„° ë§íˆ¬ ìœ ì§€
2. ëª©í‘œ ëŒ€ë¹„ ë‹¬ì„±ë¥  ì–¸ê¸‰ (ì¼ë°˜ ëª©í‘œ: 7,000~10,000ë³´/ì¼)
3. ê°€ì¥ ë§ì´ ê±¸ì€ ë‚ ê³¼ ì ê²Œ ê±¸ì€ ë‚  ì–¸ê¸‰
4. ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ì¡°ì–¸
5. 2-3ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ (ë¦¬ìŠ¤íŠ¸ ê¸ˆì§€)
"""

    resp = client.chat.completions.create(
        model=LLM_MODEL_MAIN,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=600,
        temperature=LLM_TEMPERATURE,
    )
    return resp.choices[0].message.content


def _generate_sleep_report(persona, character, raw, summaries, health_info):
    """ìˆ˜ë©´ ë¶„ì„ ë¦¬í¬íŠ¸"""

    # ì—¬ëŸ¬ ë‚ ì˜ ìˆ˜ë©´ ë°ì´í„° ì§‘ê³„
    sleep_data = []
    for day in summaries[:7]:
        day_raw = day.get("raw", {})
        sleep_data.append(
            {
                "date": day.get("date", ""),
                "sleep_hr": day_raw.get("sleep_hr", 0),
                "sleep_min": day_raw.get("sleep_min", 0),
            }
        )

    valid_sleep = [d for d in sleep_data if d["sleep_hr"] > 0]
    avg_sleep = sum(d["sleep_hr"] for d in valid_sleep) / max(len(valid_sleep), 1)

    sleep_info = health_info.get("sleep", {})

    prompt = f"""
{persona}

ì‚¬ìš©ìì˜ ìˆ˜ë©´ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

## ìˆ˜ë©´ ë°ì´í„°

### ìµœê·¼ ìˆ˜ë©´ ê¸°ë¡
{json.dumps(sleep_data, ensure_ascii=False, indent=2)}

### ì§‘ê³„
â€¢ í‰ê·  ìˆ˜ë©´: {avg_sleep:.1f}ì‹œê°„
â€¢ ìœ íš¨ ê¸°ë¡ ì¼ìˆ˜: {len(valid_sleep)}ì¼

### ìˆ˜ë©´ ìƒíƒœ ë¶„ì„
â€¢ ìƒíƒœ: {sleep_info.get('status', 'unknown')}
â€¢ ìˆ˜ì¤€: {sleep_info.get('level', '')}
â€¢ ë¶„ì„: {sleep_info.get('message', '')}
â€¢ ê¶Œì¥ì‚¬í•­: {sleep_info.get('recommendation', '')}
â€¢ ìš´ë™ ì˜í–¥: {sleep_info.get('exercise_impact', '')}

## ì‘ì„± ì§€ì¹¨
1. ìºë¦­í„° ë§íˆ¬ ìœ ì§€
2. ê¶Œì¥ ìˆ˜ë©´ ì‹œê°„(7-9ì‹œê°„) ëŒ€ë¹„ í‰ê°€
3. ìˆ˜ë©´ íŒ¨í„´ì˜ ì¼ê´€ì„± í‰ê°€
4. ìˆ˜ë©´ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ì¡°ì–¸
5. 2-3ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ (ë¦¬ìŠ¤íŠ¸ ê¸ˆì§€)
"""

    resp = client.chat.completions.create(
        model=LLM_MODEL_MAIN,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=600,
        temperature=LLM_TEMPERATURE,
    )
    return resp.choices[0].message.content


def _generate_heart_rate_report(persona, character, raw, health_info):
    """ì‹¬ë°•ìˆ˜ ë¶„ì„ ë¦¬í¬íŠ¸"""

    hr_info = health_info.get("heart_rate", {})

    prompt = f"""
{persona}

ì‚¬ìš©ìì˜ ì‹¬ë°•ìˆ˜ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

## ì‹¬ë°•ìˆ˜ ë°ì´í„°
â€¢ í‰ê·  ì‹¬ë°•ìˆ˜: {raw.get('heart_rate', 0)}bpm
â€¢ íœ´ì‹ê¸° ì‹¬ë°•ìˆ˜: {raw.get('resting_heart_rate', 0)}bpm
â€¢ ê±·ê¸° ì‹¬ë°•ìˆ˜: {raw.get('walking_heart_rate', 0)}bpm
â€¢ ì‹¬ë°•ë³€ì´ë„(HRV): {raw.get('hrv', 0)}ms

## ì‹¬ë°•ìˆ˜ ë¶„ì„
â€¢ í”¼íŠ¸ë‹ˆìŠ¤ ë ˆë²¨: {hr_info.get('fitness_level', 'unknown')}
â€¢ ë¶„ì„: {hr_info.get('message', '')}
â€¢ ìš´ë™ ê¶Œì¥: {hr_info.get('exercise_impact', '')}

## ì°¸ê³  ê¸°ì¤€
â€¢ ìš´ë™ì„ ìˆ˜: íœ´ì‹ê¸° ì‹¬ë°•ìˆ˜ 50bpm ë¯¸ë§Œ
â€¢ ë§¤ìš° ê±´ê°•: 50-60bpm
â€¢ ì–‘í˜¸: 60-70bpm
â€¢ í‰ê· : 70-80bpm
â€¢ ê°œì„  í•„ìš”: 80bpm ì´ìƒ

## ì‘ì„± ì§€ì¹¨
1. ìºë¦­í„° ë§íˆ¬ ìœ ì§€
2. í˜„ì¬ ì‹¬í ê¸°ëŠ¥ ìˆ˜ì¤€ í‰ê°€
3. íœ´ì‹ê¸° ì‹¬ë°•ìˆ˜ì˜ ì˜ë¯¸ ì„¤ëª…
4. ì‹¬í ê¸°ëŠ¥ ê°œì„ ì„ ìœ„í•œ ì¡°ì–¸
5. 2-3ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ (ë¦¬ìŠ¤íŠ¸ ê¸ˆì§€)
"""

    resp = client.chat.completions.create(
        model=LLM_MODEL_MAIN,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=600,
        temperature=LLM_TEMPERATURE,
    )
    return resp.choices[0].message.content


def _generate_health_score_report(persona, character, raw, health_info):
    """ê±´ê°• ì ìˆ˜ ë¦¬í¬íŠ¸ - ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ + LLM í•´ì„"""

    score_info = health_info.get("health_score", {})
    score = score_info.get("score", 50)
    grade = score_info.get("grade", "C")
    grade_text = score_info.get("grade_text", "ë³´í†µ")
    factors = score_info.get("factors", [])

    # ê° ì˜ì—­ë³„ ìƒíƒœ
    sleep_info = health_info.get("sleep", {})
    activity_info = health_info.get("activity", {})
    hr_info = health_info.get("heart_rate", {})
    bmi_info = health_info.get("bmi", {})

    prompt = f"""
{persona}

ì‚¬ìš©ìì˜ ì¢…í•© ê±´ê°• ì ìˆ˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

## ì¢…í•© ê±´ê°• ì ìˆ˜
ğŸ… **{score}ì  / 100ì ** ({grade}ë“±ê¸‰ - {grade_text})

## ì ìˆ˜ ì‚°ì • ìš”ì†Œ
{chr(10).join(f'â€¢ {f}' for f in factors)}

## ì˜ì—­ë³„ ìƒíƒœ
â€¢ ìˆ˜ë©´: {sleep_info.get('level', 'ë°ì´í„° ì—†ìŒ')} - {sleep_info.get('message', '')}
â€¢ í™œë™ëŸ‰: {activity_info.get('activity_level', 'ë°ì´í„° ì—†ìŒ')} - {activity_info.get('message', '')}
â€¢ ì‹¬ë°•ìˆ˜: {hr_info.get('fitness_level', 'ë°ì´í„° ì—†ìŒ')} - {hr_info.get('message', '')}
â€¢ ì²´í˜•: {bmi_info.get('category', 'ë°ì´í„° ì—†ìŒ')} - {bmi_info.get('message', '')}

## ìƒì„¸ ë°ì´í„°
â€¢ ìˆ˜ë©´: {raw.get('sleep_hr', 0)}ì‹œê°„
â€¢ ê±¸ìŒìˆ˜: {raw.get('steps', 0):,}ë³´
â€¢ ì‹¬ë°•ìˆ˜: {raw.get('heart_rate', 0)}bpm / íœ´ì‹ê¸° {raw.get('resting_heart_rate', 0)}bpm
â€¢ BMI: {raw.get('bmi', 0):.1f}

## ì‘ì„± ì§€ì¹¨
1. ìºë¦­í„° ë§íˆ¬ ìœ ì§€
2. ì ìˆ˜ì™€ ë“±ê¸‰ì˜ ì˜ë¯¸ ì„¤ëª…
3. ê°•ì  ì˜ì—­ ì¹­ì°¬
4. ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ ì¡°ì–¸
5. ì ìˆ˜ í–¥ìƒì„ ìœ„í•œ êµ¬ì²´ì  ëª©í‘œ ì œì‹œ
6. 3-4ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ (ë¦¬ìŠ¤íŠ¸ ê¸ˆì§€)
"""

    resp = client.chat.completions.create(
        model=LLM_MODEL_MAIN,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=700,
        temperature=LLM_TEMPERATURE,
    )
    return resp.choices[0].message.content
